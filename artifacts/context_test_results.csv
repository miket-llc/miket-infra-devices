test_name,model,max_input_tokens,success,latency,status_code,prompt_tokens,completion_tokens,total_tokens,error
llama31-8b-wintermute,llama31-8b-wintermute,14000,False,6.154016017913818,400,,,,"HTTP 400: {""error"":{""message"":""litellm.ContextWindowExceededError: litellm.BadRequestError: ContextWindowExceededError: OpenAIException - This model's maximum context length is 8192 tokens. However, your reques"
qwen2.5-7b-armitage,qwen2.5-7b-armitage,7000,False,5.859411954879761,500,,,,"HTTP 500: {""error"":{""message"":""litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.. Received Model Group=qwen2.5-7b-armitage\nAvailable Model Group Fallbacks=None"",""type"":null,"
wintermute-direct,casperhansen/llama-3-8b-instruct-awq,14000,False,0.02863335609436035,400,,,,"HTTP 400: {""error"":{""message"":""This model's maximum context length is 8192 tokens. However, your request has 12618 input tokens. Please reduce the length of the input messages. None"",""type"":""BadRequestError"",""p"
armitage-direct,Qwen/Qwen2.5-7B-Instruct-AWQ,7000,False,0.018834829330444336,,,,,"('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
