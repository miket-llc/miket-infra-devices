---
# Deploy LiteLLM Proxy on Motoko
# This playbook provisions and manages the LiteLLM proxy service
# which routes requests to local models (Armitage, Wintermute, Motoko) and OpenAI fallback

- name: Deploy LiteLLM proxy on motoko
  hosts: motoko
  become: true
  gather_facts: yes
  roles:
    - litellm_proxy

