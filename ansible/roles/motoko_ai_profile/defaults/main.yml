# Copyright (c) 2025 MikeT LLC. All rights reserved.

---
# Motoko AI Profile - Lightweight Embeddings + Classification
# RTX 2080 Max-Q 8GB (Turing, compute cap 7.5) with thermal constraints

# Base directory for AI services
ai_profile_base_dir: /podman/apps

# GPU thermal protection
gpu_power_limit_watts: 70  # Default 90W, cap at 70W for thermal safety
gpu_thermal_normal: 70     # Below this: all models available
gpu_thermal_hot: 80        # Above normal, below this: reduce load
gpu_thermal_critical: 85   # Above this: reject GPU requests

# =============================================================================
# EMBEDDING MODEL (served via vLLM - GPU accelerated)
# =============================================================================
# Note: TEI GPU images require compute cap 8.0+ (Ampere), RTX 2080 is 7.5 (Turing)
# Using vLLM which supports Turing GPUs

vllm_embeddings_enabled: true
vllm_embeddings_model: "BAAI/bge-base-en-v1.5"
vllm_embeddings_port: 8200
vllm_embeddings_gpu_util: 0.40
vllm_embeddings_container_name: "vllm-embeddings-motoko"
vllm_embeddings_image: "docker.io/vllm/vllm-openai:latest"

# =============================================================================
# CLASSIFICATION MODEL (served via custom FastAPI - GPU accelerated)
# =============================================================================

classifier_enabled: true
classifier_model: "MoritzLaurer/mDeBERTa-v3-base-mnli-xnli"
classifier_port: 8203
classifier_max_concurrent: 8
classifier_container_name: "classifier-motoko"

# =============================================================================
# LITELLM INTEGRATION
# =============================================================================

litellm_master_key: "sk-motoko-local"
litellm_port: 8000

# Model route names for LiteLLM
litellm_embed_bge_name: "local-motoko-embed-bge-base-en-v1-5"
litellm_classify_name: "local-motoko-classify-mdeberta-multilingual"

# =============================================================================
# RATE LIMITS
# =============================================================================

# Max requests per minute per service
rate_limit_embeddings: 600
rate_limit_classification: 120
