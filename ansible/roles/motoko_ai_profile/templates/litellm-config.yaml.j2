# {{ ansible_managed }}
# LiteLLM Configuration for Motoko AI Profile
# Routes embedding and classification requests to local services

model_list:
  # ==========================================================================
  # EMBEDDING MODELS
  # ==========================================================================
  
  # Primary embedding model - BGE Base EN v1.5 (768 dimensions)
  - model_name: {{ litellm_embed_bge_name }}
    litellm_params:
      model: huggingface/{{ tei_bge_model }}
      api_base: http://127.0.0.1:{{ tei_bge_port }}
      api_key: none
    model_info:
      description: "Primary embedding model - high quality, 768 dimensions"
      max_tokens: 512

  # Low-heat fallback - Arctic Embed XS (384 dimensions)
  - model_name: {{ litellm_embed_arctic_name }}
    litellm_params:
      model: huggingface/{{ tei_arctic_model }}
      api_base: http://127.0.0.1:{{ tei_arctic_port }}
      api_key: none
    model_info:
      description: "Low-heat fallback embedding - smaller, faster, 384 dimensions"
      max_tokens: 512

  # Alias for OpenAI compatibility
  - model_name: text-embedding-ada-002
    litellm_params:
      model: huggingface/{{ tei_bge_model }}
      api_base: http://127.0.0.1:{{ tei_bge_port }}
      api_key: none

  # ==========================================================================
  # CLASSIFICATION MODELS
  # ==========================================================================
  
  # Zero-shot classification - mDeBERTa multilingual
  - model_name: {{ litellm_classify_name }}
    litellm_params:
      model: huggingface/{{ classifier_model }}
      api_base: http://127.0.0.1:{{ classifier_port }}
      api_key: none
    model_info:
      description: "Zero-shot classification - multilingual, ~100 languages"
      max_tokens: 512

litellm_settings:
  # Drop unsupported params silently
  drop_params: true
  
  # Logging
  set_verbose: false
  
  # Request timeout
  request_timeout: 60
  
  # Rate limiting (per minute)
  max_budget: 0  # Unlimited budget for local models
  
general_settings:
  master_key: {{ litellm_master_key }}
  
  # Health check
  health_check_path: /health
  
  # Enable model info endpoint
  enable_model_info: true

