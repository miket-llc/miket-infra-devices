#!/bin/bash
# Copyright (c) 2025 MikeT LLC. All rights reserved.
#
# data-estate-status.sh
# Data Estate Status Collector
# Monitors backup freshness, B2 mirror gaps, M365 ingestion, and unknown cloud remotes
# Generates JSON and Markdown status files for Nextcloud dashboard widget
#
# Per DATA_ESTATE_SPEC from miket-infra handoff
# Deployed by Ansible data_estate_status role

set -euo pipefail

# =============================================================================
# Configuration (rendered by Ansible)
# =============================================================================

CONFIG_FILE="{{ data_estate_config_file }}"
APPROVED_REMOTES_FILE="{{ data_estate_approved_remotes_file }}"
CREDENTIALS_FILE="{{ data_estate_credentials_file }}"

JSON_OUTPUT="{{ data_estate_json_output_file }}"
MARKDOWN_OUTPUT="{{ data_estate_markdown_output_file }}"

# SLO Thresholds
SLO_SPACE_MIRROR_MAX_AGE_HOURS={{ data_estate_slo_space_mirror_max_age_hours }}
SLO_SPACE_MIRROR_WARNING_AGE_HOURS={{ data_estate_slo_space_mirror_warning_age_hours }}
SLO_SPACE_MIRROR_MAX_GAP_PERCENT={{ data_estate_slo_space_mirror_max_gap_percent }}
SLO_SPACE_MIRROR_WARNING_GAP_PERCENT={{ data_estate_slo_space_mirror_warning_gap_percent }}
SLO_RESTIC_MAX_AGE_HOURS={{ data_estate_slo_restic_snapshot_max_age_hours }}
SLO_RESTIC_WARNING_AGE_HOURS={{ data_estate_slo_restic_snapshot_warning_age_hours }}
SLO_DB_DUMP_MAX_AGE_HOURS={{ data_estate_slo_nextcloud_db_dump_max_age_hours }}
SLO_DB_DUMP_WARNING_AGE_HOURS={{ data_estate_slo_nextcloud_db_dump_warning_age_hours }}
SLO_M365_MAX_AGE_HOURS={{ data_estate_slo_m365_ingestion_max_age_hours }}
SLO_M365_WARNING_AGE_HOURS={{ data_estate_slo_m365_ingestion_warning_age_hours }}

# Paths
SPACE_PATH="{{ data_estate_b2_mirror_source }}"
B2_BUCKET="{{ data_estate_b2_mirror_bucket }}"
DB_BACKUP_PATH="{{ data_estate_nextcloud_db_backup_path }}"
M365_INGESTION_PATH="{{ data_estate_m365_ingestion_path }}"
RESTIC_LOCAL_REPO="/space/snapshots/flux-local"
RESTIC_LOCAL_PASS="/root/.restic-local-pass"

# Service names for journal parsing
SERVICE_SPACE_MIRROR="{{ data_estate_service_space_mirror }}"
SERVICE_FLUX_BACKUP="{{ data_estate_service_flux_backup }}"
SERVICE_FLUX_LOCAL="{{ data_estate_service_flux_local }}"
SERVICE_M365_SYNC="{{ data_estate_service_m365_sync }}"
SERVICE_DB_BACKUP="{{ data_estate_service_db_backup }}"

# Approved remotes (space-separated list)
APPROVED_REMOTES="{{ data_estate_approved_remotes | map(attribute='name') | join(' ') }}"

{% raw %}
# =============================================================================
# Globals for status tracking
# =============================================================================

OVERALL_STATUS="OK"
CHECKS_PASSED=0
CHECKS_TOTAL=0
declare -A CHECK_RESULTS

# =============================================================================
# Helper Functions
# =============================================================================

log() {
    echo "[$(date -Iseconds)] $*"
}

error() {
    echo "[$(date -Iseconds)] ERROR: $*" >&2
}

# Load credentials from env file
load_credentials() {
    if [[ -f "$CREDENTIALS_FILE" ]]; then
        # shellcheck source=/dev/null
        source "$CREDENTIALS_FILE"
        log "Loaded credentials from $CREDENTIALS_FILE"
    else
        error "Credentials file not found: $CREDENTIALS_FILE"
        return 1
    fi
}

# Get hours since a timestamp
hours_since() {
    local timestamp="$1"
    local now
    local then
    now=$(date +%s)
    then=$(date -d "$timestamp" +%s 2>/dev/null || echo 0)
    if [[ "$then" -eq 0 ]]; then
        echo "-1"
        return
    fi
    echo $(( (now - then) / 3600 ))
}

# Get last successful run time from systemd journal
get_service_last_success() {
    local service="$1"
    local last_entry
    
    # Get the last journal entry for the service with exit status 0
    last_entry=$(journalctl -u "$service" --no-pager -n 100 --output=json 2>/dev/null | \
        jq -rs '[.[] | select(.MESSAGE != null and (.MESSAGE | test("Complete|completed|success"; "i")))] | last | .__REALTIME_TIMESTAMP // empty' 2>/dev/null || echo "")
    
    if [[ -n "$last_entry" ]]; then
        # Convert microseconds to seconds and format as ISO timestamp
        local seconds=$((last_entry / 1000000))
        date -d "@$seconds" -Iseconds 2>/dev/null || echo ""
    else
        # Fallback: get last invocation time from systemctl
        systemctl show "$service" --property=ExecMainExitTimestamp --value 2>/dev/null | \
            sed 's/ [A-Z]*$//' || echo ""
    fi
}

# Update overall status (escalates: OK -> WARNING -> CRITICAL)
update_overall_status() {
    local new_status="$1"
    case "$new_status" in
        CRITICAL)
            OVERALL_STATUS="CRITICAL"
            ;;
        WARNING)
            if [[ "$OVERALL_STATUS" != "CRITICAL" ]]; then
                OVERALL_STATUS="WARNING"
            fi
            ;;
    esac
}

# Record check result
record_check() {
    local name="$1"
    local status="$2"
    local value="$3"
    local threshold="$4"
    local message="$5"
    
    CHECKS_TOTAL=$((CHECKS_TOTAL + 1))
    if [[ "$status" == "OK" ]]; then
        CHECKS_PASSED=$((CHECKS_PASSED + 1))
    fi
    
    CHECK_RESULTS["${name}_status"]="$status"
    CHECK_RESULTS["${name}_value"]="$value"
    CHECK_RESULTS["${name}_threshold"]="$threshold"
    CHECK_RESULTS["${name}_message"]="$message"
    
    update_overall_status "$status"
    log "Check $name: $status ($message)"
}

# Format bytes to human readable
format_bytes() {
    local bytes="$1"
    if [[ "$bytes" -ge 1099511627776 ]]; then
        echo "$(echo "scale=2; $bytes / 1099511627776" | bc) TiB"
    elif [[ "$bytes" -ge 1073741824 ]]; then
        echo "$(echo "scale=2; $bytes / 1073741824" | bc) GiB"
    elif [[ "$bytes" -ge 1048576 ]]; then
        echo "$(echo "scale=2; $bytes / 1048576" | bc) MiB"
    else
        echo "$bytes bytes"
    fi
}

# =============================================================================
# Check Functions
# =============================================================================

check_restic_cloud_snapshot() {
    log "Checking restic cloud snapshot age..."
    
    local repo="b2:miket-backups-restic:flux"
    local last_snapshot_time=""
    local age_hours=-1
    local status="CRITICAL"
    local message=""
    
    # First check if restic is installed
    if ! command -v restic &>/dev/null; then
        status="WARNING"
        message="restic not installed (deploy data-lifecycle role)"
        record_check "restic_cloud_age" "$status" "$age_hours" "$SLO_RESTIC_MAX_AGE_HOURS" "$message"
        return
    fi
    
    if [[ -z "${RESTIC_PASSWORD:-}" ]] || [[ -z "${B2_ACCOUNT_ID:-}" ]] || [[ -z "${B2_ACCOUNT_KEY:-}" ]]; then
        message="Missing B2/restic credentials"
        record_check "restic_cloud_age" "$status" "$age_hours" "$SLO_RESTIC_MAX_AGE_HOURS" "$message"
        return
    fi
    
    # Get latest snapshot
    local snapshot_json
    if snapshot_json=$(restic -r "$repo" snapshots --json --latest 1 2>/dev/null); then
        last_snapshot_time=$(echo "$snapshot_json" | jq -r '.[0].time // empty' 2>/dev/null || echo "")
        if [[ -n "$last_snapshot_time" ]]; then
            age_hours=$(hours_since "$last_snapshot_time")
            if [[ "$age_hours" -lt 0 ]]; then
                status="CRITICAL"
                message="Unable to parse snapshot time"
            elif [[ "$age_hours" -le "$SLO_RESTIC_WARNING_AGE_HOURS" ]]; then
                status="OK"
                message="${age_hours}h ago (within ${SLO_RESTIC_MAX_AGE_HOURS}h RPO)"
            elif [[ "$age_hours" -le "$SLO_RESTIC_MAX_AGE_HOURS" ]]; then
                status="WARNING"
                message="${age_hours}h ago (approaching ${SLO_RESTIC_MAX_AGE_HOURS}h RPO)"
            else
                status="CRITICAL"
                message="${age_hours}h ago (exceeds ${SLO_RESTIC_MAX_AGE_HOURS}h RPO)"
            fi
        else
            status="WARNING"
            message="No snapshots found in repository"
        fi
    else
        message="Unable to connect to restic repository"
    fi
    
    record_check "restic_cloud_age" "$status" "$age_hours" "$SLO_RESTIC_MAX_AGE_HOURS" "$message"
}

check_restic_local_snapshot() {
    log "Checking restic local snapshot age..."
    
    local repo="$RESTIC_LOCAL_REPO"
    local last_snapshot_time=""
    local age_hours=-1
    local status="CRITICAL"
    local message=""
    
    # First check if restic is installed
    if ! command -v restic &>/dev/null; then
        status="WARNING"
        message="restic not installed (deploy data-lifecycle role)"
        record_check "restic_local_age" "$status" "$age_hours" "$SLO_RESTIC_MAX_AGE_HOURS" "$message"
        return
    fi
    
    if [[ ! -d "$repo" ]]; then
        status="WARNING"
        message="Local restic repo not initialized: $repo (deploy data-lifecycle role)"
        record_check "restic_local_age" "$status" "$age_hours" "$SLO_RESTIC_MAX_AGE_HOURS" "$message"
        return
    fi
    
    if [[ ! -f "$RESTIC_LOCAL_PASS" ]]; then
        message="Local restic password file not found"
        record_check "restic_local_age" "$status" "$age_hours" "$SLO_RESTIC_MAX_AGE_HOURS" "$message"
        return
    fi
    
    # Get latest snapshot
    local snapshot_json
    if snapshot_json=$(restic -r "$repo" --password-file "$RESTIC_LOCAL_PASS" snapshots --json --latest 1 2>/dev/null); then
        last_snapshot_time=$(echo "$snapshot_json" | jq -r '.[0].time // empty' 2>/dev/null || echo "")
        if [[ -n "$last_snapshot_time" ]]; then
            age_hours=$(hours_since "$last_snapshot_time")
            if [[ "$age_hours" -lt 0 ]]; then
                status="CRITICAL"
                message="Unable to parse snapshot time"
            elif [[ "$age_hours" -le "$SLO_RESTIC_WARNING_AGE_HOURS" ]]; then
                status="OK"
                message="${age_hours}h ago (within ${SLO_RESTIC_MAX_AGE_HOURS}h RPO)"
            elif [[ "$age_hours" -le "$SLO_RESTIC_MAX_AGE_HOURS" ]]; then
                status="WARNING"
                message="${age_hours}h ago (approaching ${SLO_RESTIC_MAX_AGE_HOURS}h RPO)"
            else
                status="CRITICAL"
                message="${age_hours}h ago (exceeds ${SLO_RESTIC_MAX_AGE_HOURS}h RPO)"
            fi
        else
            status="WARNING"
            message="No snapshots found in local repository"
        fi
    else
        message="Unable to read local restic repository"
    fi
    
    record_check "restic_local_age" "$status" "$age_hours" "$SLO_RESTIC_MAX_AGE_HOURS" "$message"
}

check_space_mirror_age() {
    log "Checking space mirror sync age..."
    
    local last_sync=""
    local age_hours=-1
    local status="CRITICAL"
    local message=""
    
    # Check if service exists
    if ! systemctl list-unit-files "$SERVICE_SPACE_MIRROR" &>/dev/null; then
        status="WARNING"
        message="Space mirror service not configured (deploy data-lifecycle role)"
        record_check "space_mirror_age" "$status" "$age_hours" "$SLO_SPACE_MIRROR_MAX_AGE_HOURS" "$message"
        return
    fi
    
    # Try to get last successful sync from journal
    last_sync=$(get_service_last_success "$SERVICE_SPACE_MIRROR")
    
    if [[ -n "$last_sync" ]]; then
        age_hours=$(hours_since "$last_sync")
        if [[ "$age_hours" -lt 0 ]]; then
            status="CRITICAL"
            message="Unable to parse last sync time"
        elif [[ "$age_hours" -le "$SLO_SPACE_MIRROR_WARNING_AGE_HOURS" ]]; then
            status="OK"
            message="${age_hours}h ago (within ${SLO_SPACE_MIRROR_MAX_AGE_HOURS}h RPO)"
        elif [[ "$age_hours" -le "$SLO_SPACE_MIRROR_MAX_AGE_HOURS" ]]; then
            status="WARNING"
            message="${age_hours}h ago (approaching ${SLO_SPACE_MIRROR_MAX_AGE_HOURS}h RPO)"
        else
            status="CRITICAL"
            message="${age_hours}h ago (exceeds ${SLO_SPACE_MIRROR_MAX_AGE_HOURS}h RPO)"
        fi
    else
        status="WARNING"
        message="No successful sync found in journal (service may not have run yet)"
    fi
    
    record_check "space_mirror_age" "$status" "$age_hours" "$SLO_SPACE_MIRROR_MAX_AGE_HOURS" "$message"
}

check_space_mirror_gap() {
    log "Checking space mirror size gap..."
    
    local local_bytes=0
    local remote_bytes=0
    local gap_bytes=0
    local gap_percent=0
    local status="CRITICAL"
    local message=""
    local direction=""
    
    if [[ -z "${B2_APPLICATION_KEY_ID:-}" ]] || [[ -z "${B2_APPLICATION_KEY:-}" ]]; then
        message="Missing B2 credentials for mirror check"
        record_check "space_mirror_gap" "$status" "$gap_percent" "$SLO_SPACE_MIRROR_MAX_GAP_PERCENT" "$message"
        return
    fi
    
    # Get local size
    if [[ -d "$SPACE_PATH" ]]; then
        local_bytes=$(du -sb "$SPACE_PATH" 2>/dev/null | awk '{print $1}' || echo 0)
    fi
    
    if [[ "$local_bytes" -eq 0 ]]; then
        message="Unable to determine local /space size"
        record_check "space_mirror_gap" "$status" "$gap_percent" "$SLO_SPACE_MIRROR_MAX_GAP_PERCENT" "$message"
        return
    fi
    
    # Get remote size using rclone with backend notation
    export RCLONE_B2_ACCOUNT="${B2_APPLICATION_KEY_ID}"
    export RCLONE_B2_KEY="${B2_APPLICATION_KEY}"
    
    local remote_json
    if remote_json=$(rclone size ":b2:${B2_BUCKET}" --json 2>/dev/null); then
        remote_bytes=$(echo "$remote_json" | jq -r '.bytes // 0' 2>/dev/null || echo 0)
    fi
    
    if [[ "$remote_bytes" -eq 0 ]]; then
        message="Unable to determine B2 mirror size (may be empty or unreachable)"
        status="WARNING"
        record_check "space_mirror_gap" "$status" "$gap_percent" "$SLO_SPACE_MIRROR_MAX_GAP_PERCENT" "$message"
        return
    fi
    
    # Calculate gap and direction
    local raw_gap=$((local_bytes - remote_bytes))
    if [[ "$raw_gap" -lt 0 ]]; then
        gap_bytes=$((-raw_gap))
        direction="remote_larger"
    else
        gap_bytes=$raw_gap
        direction="local_larger"
    fi
    
    # Calculate percentage relative to the larger of the two
    local base_bytes=$local_bytes
    if [[ "$remote_bytes" -gt "$local_bytes" ]]; then
        base_bytes=$remote_bytes
    fi
    gap_percent=$(echo "scale=2; ($gap_bytes / $base_bytes) * 100" | bc 2>/dev/null || echo "0")
    
    # Format sizes for display
    local local_human remote_human gap_human
    local_human=$(format_bytes "$local_bytes")
    remote_human=$(format_bytes "$remote_bytes")
    gap_human=$(format_bytes "$gap_bytes")
    
    # Determine status
    local gap_float
    gap_float=$(echo "$gap_percent" | sed 's/^\./0./')
    
    # Build message with direction context
    local direction_msg=""
    if [[ "$direction" == "remote_larger" ]]; then
        direction_msg="Remote has more data than local"
    else
        direction_msg="Local has more data than remote"
    fi
    
    if (( $(echo "$gap_float <= $SLO_SPACE_MIRROR_WARNING_GAP_PERCENT" | bc -l) )); then
        status="OK"
        message="Gap: ${gap_percent}% (${gap_human}) - Local: ${local_human}, Remote: ${remote_human}"
    elif (( $(echo "$gap_float <= $SLO_SPACE_MIRROR_MAX_GAP_PERCENT" | bc -l) )); then
        status="WARNING"
        message="Gap: ${gap_percent}% (${gap_human}) - ${direction_msg}"
    else
        status="CRITICAL"
        message="Gap: ${gap_percent}% (${gap_human}) - ${direction_msg}. Local: ${local_human}, Remote: ${remote_human}"
    fi
    
    record_check "space_mirror_gap" "$status" "$gap_percent" "$SLO_SPACE_MIRROR_MAX_GAP_PERCENT" "$message"
}

check_nextcloud_db_dump() {
    log "Checking Nextcloud DB dump age..."
    
    local latest_dump=""
    local age_hours=-1
    local status="CRITICAL"
    local message=""
    
    if [[ ! -d "$DB_BACKUP_PATH" ]]; then
        status="WARNING"
        message="DB backup directory not found (deploy nextcloud_server role with db_backup)"
        record_check "nextcloud_db_age" "$status" "$age_hours" "$SLO_DB_DUMP_MAX_AGE_HOURS" "$message"
        return
    fi
    
    # Find latest dump file
    latest_dump=$(find "$DB_BACKUP_PATH" -name "*.dump" -o -name "*.sql" -o -name "*.sql.gz" 2>/dev/null | \
        xargs -r ls -t 2>/dev/null | head -1 || echo "")
    
    if [[ -z "$latest_dump" ]]; then
        status="WARNING"
        message="No database dump files found in $DB_BACKUP_PATH"
        record_check "nextcloud_db_age" "$status" "$age_hours" "$SLO_DB_DUMP_MAX_AGE_HOURS" "$message"
        return
    fi
    
    # Get file modification time
    local file_time
    file_time=$(stat -c %Y "$latest_dump" 2>/dev/null || echo 0)
    if [[ "$file_time" -gt 0 ]]; then
        local now
        now=$(date +%s)
        age_hours=$(( (now - file_time) / 3600 ))
        
        if [[ "$age_hours" -le "$SLO_DB_DUMP_WARNING_AGE_HOURS" ]]; then
            status="OK"
            message="${age_hours}h ago (within ${SLO_DB_DUMP_MAX_AGE_HOURS}h RPO)"
        elif [[ "$age_hours" -le "$SLO_DB_DUMP_MAX_AGE_HOURS" ]]; then
            status="WARNING"
            message="${age_hours}h ago (approaching ${SLO_DB_DUMP_MAX_AGE_HOURS}h RPO)"
        else
            status="CRITICAL"
            message="${age_hours}h ago (exceeds ${SLO_DB_DUMP_MAX_AGE_HOURS}h RPO)"
        fi
    else
        message="Unable to determine dump file age"
    fi
    
    record_check "nextcloud_db_age" "$status" "$age_hours" "$SLO_DB_DUMP_MAX_AGE_HOURS" "$message"
}

check_m365_ingestion() {
    log "Checking M365 ingestion age..."
    
    local last_sync=""
    local age_hours=-1
    local status="CRITICAL"
    local message=""
    
    # Check if M365 sync service exists
    if ! systemctl list-unit-files "$SERVICE_M365_SYNC" &>/dev/null; then
        status="WARNING"
        message="M365 sync service not configured"
        record_check "m365_ingestion_age" "$status" "$age_hours" "$SLO_M365_MAX_AGE_HOURS" "$message"
        return
    fi
    
    # Try to get last successful sync from journal
    last_sync=$(get_service_last_success "$SERVICE_M365_SYNC")
    
    if [[ -n "$last_sync" ]]; then
        age_hours=$(hours_since "$last_sync")
        if [[ "$age_hours" -lt 0 ]]; then
            status="CRITICAL"
            message="Unable to parse last sync time"
        elif [[ "$age_hours" -le "$SLO_M365_WARNING_AGE_HOURS" ]]; then
            status="OK"
            message="${age_hours}h ago (within ${SLO_M365_MAX_AGE_HOURS}h RPO)"
        elif [[ "$age_hours" -le "$SLO_M365_MAX_AGE_HOURS" ]]; then
            status="WARNING"
            message="${age_hours}h ago (approaching ${SLO_M365_MAX_AGE_HOURS}h RPO)"
        else
            status="CRITICAL"
            message="${age_hours}h ago (exceeds ${SLO_M365_MAX_AGE_HOURS}h RPO)"
        fi
    else
        # Fallback: check directory modification time
        if [[ -d "$M365_INGESTION_PATH" ]]; then
            local dir_time
            dir_time=$(stat -c %Y "$M365_INGESTION_PATH" 2>/dev/null || echo 0)
            if [[ "$dir_time" -gt 0 ]]; then
                local now
                now=$(date +%s)
                age_hours=$(( (now - dir_time) / 3600 ))
                status="WARNING"
                message="No journal entry; directory last modified ${age_hours}h ago"
            else
                status="WARNING"
                message="No sync history found"
            fi
        else
            status="WARNING"
            message="M365 ingestion directory not found: $M365_INGESTION_PATH"
        fi
    fi
    
    record_check "m365_ingestion_age" "$status" "$age_hours" "$SLO_M365_MAX_AGE_HOURS" "$message"
}

check_unknown_remotes() {
    log "Checking for unknown cloud remotes..."
    
    local unknown_count=0
    local unknown_list=""
    local status="OK"
    local message=""
    
    # Check if rclone is installed
    if ! command -v rclone &>/dev/null; then
        status="WARNING"
        message="rclone not installed - cannot check remotes"
        record_check "unknown_remotes" "$status" "$unknown_count" "0" "$message"
        return
    fi
    
    # Get all configured rclone remotes
    # Note: We check both user config and system config locations
    local configured_remotes=""
    local config_found=false
    
    # Try user config first
    if [[ -f "$HOME/.config/rclone/rclone.conf" ]]; then
        configured_remotes=$(rclone config dump --json 2>/dev/null | jq -r 'keys[]' 2>/dev/null || echo "")
        config_found=true
    fi
    
    # Try system config
    if [[ -f "/etc/rclone.conf" ]] && [[ -z "$configured_remotes" ]]; then
        configured_remotes=$(RCLONE_CONFIG=/etc/rclone.conf rclone config dump --json 2>/dev/null | jq -r 'keys[]' 2>/dev/null || echo "")
        config_found=true
    fi
    
    # If no config file found, that's OK - we use backend notation with env vars
    if [[ "$config_found" == "false" ]] && [[ -z "$configured_remotes" ]]; then
        status="OK"
        message="No rclone config file (using backend notation with env vars - OK)"
        CHECK_RESULTS["unknown_remotes_list"]="[]"
        record_check "unknown_remotes" "$status" "$unknown_count" "0" "$message"
        return
    fi
    
    if [[ -z "$configured_remotes" ]]; then
        status="OK"
        message="No rclone remotes configured"
        CHECK_RESULTS["unknown_remotes_list"]="[]"
        record_check "unknown_remotes" "$status" "$unknown_count" "0" "$message"
        return
    fi
    
    # Check each remote against approved list
    local unknown_remotes=()
    for remote in $configured_remotes; do
        local is_approved=false
        for approved in $APPROVED_REMOTES; do
            if [[ "$remote" == "$approved" ]]; then
                is_approved=true
                break
            fi
        done
        if [[ "$is_approved" == "false" ]]; then
            unknown_remotes+=("$remote")
        fi
    done
    
    unknown_count=${#unknown_remotes[@]}
    
    if [[ "$unknown_count" -eq 0 ]]; then
        status="OK"
        message="All configured remotes are approved"
    else
        status="CRITICAL"
        unknown_list=$(printf '%s, ' "${unknown_remotes[@]}" | sed 's/, $//')
        message="Found $unknown_count unknown remote(s): $unknown_list"
    fi
    
    # Store unknown remotes list for JSON output
    CHECK_RESULTS["unknown_remotes_list"]=$(printf '%s\n' "${unknown_remotes[@]}" | jq -R . | jq -s . 2>/dev/null || echo "[]")
    
    record_check "unknown_remotes" "$status" "$unknown_count" "0" "$message"
}

# =============================================================================
# Output Generation
# =============================================================================

generate_json_output() {
    log "Generating JSON output..."
    
    local compliance_pct=0
    if [[ "$CHECKS_TOTAL" -gt 0 ]]; then
        compliance_pct=$(echo "scale=1; ($CHECKS_PASSED / $CHECKS_TOTAL) * 100" | bc 2>/dev/null || echo "0")
    fi
    
    cat > "$JSON_OUTPUT" << JSONEOF
{
  "generated_at": "$(date -Iseconds)",
  "overall_status": "$OVERALL_STATUS",
  "slo_compliance": {
    "passed": $CHECKS_PASSED,
    "total": $CHECKS_TOTAL,
    "percentage": $compliance_pct
  },
  "checks": {
    "restic_cloud_age": {
      "status": "${CHECK_RESULTS[restic_cloud_age_status]:-UNKNOWN}",
      "value_hours": ${CHECK_RESULTS[restic_cloud_age_value]:--1},
      "threshold_hours": ${CHECK_RESULTS[restic_cloud_age_threshold]:-24},
      "message": "${CHECK_RESULTS[restic_cloud_age_message]:-No data}"
    },
    "restic_local_age": {
      "status": "${CHECK_RESULTS[restic_local_age_status]:-UNKNOWN}",
      "value_hours": ${CHECK_RESULTS[restic_local_age_value]:--1},
      "threshold_hours": ${CHECK_RESULTS[restic_local_age_threshold]:-24},
      "message": "${CHECK_RESULTS[restic_local_age_message]:-No data}"
    },
    "space_mirror_age": {
      "status": "${CHECK_RESULTS[space_mirror_age_status]:-UNKNOWN}",
      "value_hours": ${CHECK_RESULTS[space_mirror_age_value]:--1},
      "threshold_hours": ${CHECK_RESULTS[space_mirror_age_threshold]:-24},
      "message": "${CHECK_RESULTS[space_mirror_age_message]:-No data}"
    },
    "space_mirror_gap": {
      "status": "${CHECK_RESULTS[space_mirror_gap_status]:-UNKNOWN}",
      "value_percent": ${CHECK_RESULTS[space_mirror_gap_value]:-0},
      "threshold_percent": ${CHECK_RESULTS[space_mirror_gap_threshold]:-5},
      "message": "${CHECK_RESULTS[space_mirror_gap_message]:-No data}"
    },
    "nextcloud_db_age": {
      "status": "${CHECK_RESULTS[nextcloud_db_age_status]:-UNKNOWN}",
      "value_hours": ${CHECK_RESULTS[nextcloud_db_age_value]:--1},
      "threshold_hours": ${CHECK_RESULTS[nextcloud_db_age_threshold]:-24},
      "message": "${CHECK_RESULTS[nextcloud_db_age_message]:-No data}"
    },
    "m365_ingestion_age": {
      "status": "${CHECK_RESULTS[m365_ingestion_age_status]:-UNKNOWN}",
      "value_hours": ${CHECK_RESULTS[m365_ingestion_age_value]:--1},
      "threshold_hours": ${CHECK_RESULTS[m365_ingestion_age_threshold]:-24},
      "message": "${CHECK_RESULTS[m365_ingestion_age_message]:-No data}"
    },
    "unknown_remotes": {
      "status": "${CHECK_RESULTS[unknown_remotes_status]:-UNKNOWN}",
      "count": ${CHECK_RESULTS[unknown_remotes_value]:-0},
      "remotes": ${CHECK_RESULTS[unknown_remotes_list]:-[]},
      "message": "${CHECK_RESULTS[unknown_remotes_message]:-No data}"
    }
  }
}
JSONEOF
    
    log "JSON output written to $JSON_OUTPUT"
}

generate_markdown_output() {
    log "Generating Markdown output..."
    
    # Status emoji mapping
    local overall_emoji="?"
    case "$OVERALL_STATUS" in
        OK) overall_emoji="OK" ;;
        WARNING) overall_emoji="WARN" ;;
        CRITICAL) overall_emoji="CRIT" ;;
    esac
    
    # Helper function for status emoji
    status_indicator() {
        case "$1" in
            OK) echo "[OK]" ;;
            WARNING) echo "[WARN]" ;;
            CRITICAL) echo "[CRIT]" ;;
            *) echo "[?]" ;;
        esac
    }
    
    cat > "$MARKDOWN_OUTPUT" << MDEOF
# Data Estate Health Summary

**Last Updated:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')  
**Overall Status:** **$overall_emoji**  
**SLO Compliance:** $CHECKS_PASSED / $CHECKS_TOTAL checks passed

---

## Backups (Restic)

### Cloud Backup (/flux to B2)
$(status_indicator "${CHECK_RESULTS[restic_cloud_age_status]:-UNKNOWN}") ${CHECK_RESULTS[restic_cloud_age_message]:-No data}

### Local Snapshots (/flux to /space/snapshots)
$(status_indicator "${CHECK_RESULTS[restic_local_age_status]:-UNKNOWN}") ${CHECK_RESULTS[restic_local_age_message]:-No data}

---

## B2 Mirror (/space to miket-space-mirror)

### Sync Age
$(status_indicator "${CHECK_RESULTS[space_mirror_age_status]:-UNKNOWN}") ${CHECK_RESULTS[space_mirror_age_message]:-No data}

### Size Gap
$(status_indicator "${CHECK_RESULTS[space_mirror_gap_status]:-UNKNOWN}") ${CHECK_RESULTS[space_mirror_gap_message]:-No data}

---

## Nextcloud Database

$(status_indicator "${CHECK_RESULTS[nextcloud_db_age_status]:-UNKNOWN}") ${CHECK_RESULTS[nextcloud_db_age_message]:-No data}

---

## M365 Ingestion (OneDrive to /space/mike/inbox/ms365)

$(status_indicator "${CHECK_RESULTS[m365_ingestion_age_status]:-UNKNOWN}") ${CHECK_RESULTS[m365_ingestion_age_message]:-No data}

---

## Cloud Inventory

$(status_indicator "${CHECK_RESULTS[unknown_remotes_status]:-UNKNOWN}") ${CHECK_RESULTS[unknown_remotes_message]:-No data}

---

*Generated by data-estate-status collector on $(hostname)*  
*Config: $CONFIG_FILE*
MDEOF
    
    log "Markdown output written to $MARKDOWN_OUTPUT"
}

# =============================================================================
# Main
# =============================================================================

main() {
    log "Starting Data Estate Status Collector..."
    
    # Load credentials
    if ! load_credentials; then
        error "Failed to load credentials. Some checks will fail."
    fi
    
    # Run all checks
    check_restic_cloud_snapshot
    check_restic_local_snapshot
    check_space_mirror_age
    check_space_mirror_gap
    check_nextcloud_db_dump
    check_m365_ingestion
    check_unknown_remotes
    
    # Generate outputs
    generate_json_output
    generate_markdown_output
    
    # Summary
    log "Data Estate Status Collection Complete"
    log "Overall Status: $OVERALL_STATUS"
    log "SLO Compliance: $CHECKS_PASSED / $CHECKS_TOTAL checks passed"
    
    # Exit with appropriate code
    # WARNING is acceptable (not a failure), only CRITICAL causes non-zero exit
    case "$OVERALL_STATUS" in
        OK)
            exit 0
            ;;
        WARNING)
            exit 0  # Warnings are informational, not failures
            ;;
        CRITICAL)
            exit 1  # Critical issues should be flagged
            ;;
    esac
}

main "$@"
{% endraw %}
