# Copyright (c) 2025 MikeT LLC. All rights reserved.

---
# LiteLLM Proxy Configuration for Motoko
# Override secrets at runtime or via Ansible Vault

# LiteLLM version (pinned for stability)
litellm_version: "latest"

# Network binding
litellm_bind_host: "0.0.0.0"
litellm_port: 8000

# Backend service URLs (using Tailscale FQDNs for security and resilience)
# Workstations: Ollama on port 11434 (no /v1 suffix for ollama/ provider)
# Servers: vLLM on dedicated ports (embeddings only on motoko for now)
armitage_base_url: "http://armitage.pangolin-vega.ts.net:11434"
wintermute_base_url: "http://wintermute.pangolin-vega.ts.net:11434"
countzero_base_url: "http://count-zero.pangolin-vega.ts.net:11434"
motoko_embed_base_url: "http://motoko.pangolin-vega.ts.net:8200/v1"

# Wintermute model config (Ollama with llama3-8k - custom with explicit 8k context)
wintermute_model_name: "llama3-8k"
wintermute_model_display: "ollama/llama3-8k"
wintermute_max_model_len: 8192
wintermute_max_input_tokens: 7000
wintermute_max_output_tokens: 1000
wintermute_max_concurrent_requests: 2

# Armitage model config (Ollama with qwen2.5-8k - custom with explicit 8k context)
armitage_model_name: "qwen2.5-8k"
armitage_model_display: "ollama/qwen2.5-8k"
armitage_max_model_len: 8192
armitage_max_input_tokens: 7000
armitage_max_output_tokens: 768
armitage_max_concurrent_requests: 1

# Count-zero model config (Ollama with qwen2.5-32k - 32k context, fast on M1 Max)
countzero_model_name: "qwen2.5-32k"
countzero_model_display: "ollama/qwen2.5-32k"
countzero_max_model_len: 32768
countzero_max_input_tokens: 30000
countzero_max_output_tokens: 2048
countzero_max_concurrent_requests: 2

# OpenAI configuration
openai_strong_model: "gpt-4.1-mini"
openai_cheap_model: "gpt-4o-mini"
openai_budget_monthly_usd: 150

# Secrets supplied via env files generated from Azure Key Vault
openai_api_key: "{{ lookup('env', 'OPENAI_API_KEY') | default('__SECRET_OPENAI_API_KEY__', true) }}"
litellm_bearer_token: "{{ lookup('env', 'LITELLM_TOKEN') | default('__SECRET_LITELLM_TOKEN__', true) }}"
