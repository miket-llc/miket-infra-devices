# Copyright (c) 2025 MikeT LLC. All rights reserved.

# Wintermute - Windows Desktop Workstation
# Last Updated: 2025-11-08

device:
  hostname: wintermute
  type: desktop
  location: fixed
  primary_user: mdt

hardware:
  cpu: "Intel Core i9 (high-performance)"
  gpu: "NVIDIA GeForce RTX 4070 Super (12GB VRAM)"
  memory: "32GB+ DDR5"
  storage:
    - "NVMe SSD (Primary)"
    - "Additional storage as needed"

operating_system:
  os: Windows 11 Pro
  version: Latest
  wsl: true
  docker_desktop: false  # BANNED - Docker purged 2025-12-03

network:
  tailscale_enabled: true
  remote_desktop: true
  wake_on_lan: true

services:
  - Podman Desktop (container runtime)
  - NVIDIA CUDA Toolkit
  - WSL2 (Ubuntu 24.04 LTS)
  - NVIDIA Container Toolkit (via WSL2)
  - Steam/Gaming platforms
  - Development IDEs (VS Code, Cursor)
  - Streaming software (OBS, etc.)
  - Flight simulators

use_cases:
  - Primary development workstation
  - High-performance gaming
  - Streaming (gaming/content creation)
  - Flight simulation
  - CUDA/ML development
  - Podman containerization
  - vLLM inference serving
  - Remote access via Tailscale

vllm:
  enabled: true
  model: "casperhansen/llama-3-8b-instruct-awq"
  served_model_name: "llama31-8b-wintermute"
  port: 8000
  container_name: "vllm-wintermute"
  image: "vllm/vllm-openai:latest"
  max_model_len: 8192
  max_num_seqs: 2
  gpu_memory_utilization: 0.88
  quantization: "awq"
  tensor_parallel_size: 1
  auto_switch: true
  check_interval_minutes: 5
  idle_threshold_minutes: 5

notes:
  - High-performance desktop workstation with RTX 4070 Super
  - Optimized for gaming, streaming, development, and vLLM serving
  - Supports GPU passthrough to WSL2 for CUDA workloads
  - Connected to Tailnet for secure remote access
  - Gaming mode optimizations available via Windows Game Mode
  - vLLM serving with automatic mode switching between workstation and LLM modes
  - Can host larger models than Armitage due to 12GB VRAM
